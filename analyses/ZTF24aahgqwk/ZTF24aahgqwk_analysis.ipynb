{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c91c95d",
   "metadata": {},
   "source": [
    "# ZTF24aahgqwk in NGC 3443\n",
    "\n",
    "### Observation Notes\n",
    "\n",
    "Typically a session has 60 30-second exposures in each of r' and g', but starting with\n",
    "2024-04-21, there are 120 of g', because g' images were getting fainter.\n",
    "\n",
    "[ZTF24aahgwk Observation Log](https://brianhill.github.io/supernova-observation/analyses/ZTF24aahgqwk/ZTF24aahgqwk_observation_log.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9d239c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS COMMENT IS THE LONGEST A LINE CAN BE AND STILL RENDER COMPLETELY WHEN PRINTING IN LANDSCAPE MODE.\n",
    "\n",
    "import os\n",
    "\n",
    "observations_directory = os.path.join(os.path.expanduser('~'), '2024 Sessions')\n",
    "analysis_directory = os.path.join(os.path.expanduser('~'), 'ZTF24aahgqwk_analysis')\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from astropy import units as u\n",
    "from astropy.nddata import CCDData\n",
    "from astropy.io import fits\n",
    "from ccdproc import ImageFileCollection, combine, subtract_dark, flat_correct # Combiner\n",
    "import astroalign as aa\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# filters\n",
    "\n",
    "filters = ['g', 'r']\n",
    "filter_full_names = [\"Sloan g'\", \"Sloan r'\"]\n",
    "\n",
    "SLOAN_G_FILTER = 0\n",
    "SLOAN_R_FILTER = 1\n",
    "\n",
    "# exposure durations\n",
    "\n",
    "light_exposure = 30 * u.second\n",
    "flat_exposure = 0.1 * u.second\n",
    "dark_exposure = light_exposure  # our method presumes this equality\n",
    "bias_exposure = flat_exposure  # our method presumes this equality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c0228c",
   "metadata": {},
   "source": [
    "## Combine the Calibration Images into Masters\n",
    "\n",
    "### Calibration Images\n",
    "\n",
    "The calibration images are in ~/2024 Sessions/2024-04-12/. In turn, ~/2024 Sessions is\n",
    "actually a soft link to /Volumes/Astronomy Data/2024 Sessions/2024 Sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe69b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the date on which the calibration images were taken\n",
    "\n",
    "calibration_date = '2024-04-12'\n",
    "\n",
    "# calibration directory\n",
    "\n",
    "calibration_directory = os.path.join(observations_directory, calibration_date)\n",
    "\n",
    "# subdirectory for the 30-second darks\n",
    "\n",
    "dark_directory = os.path.join(calibration_directory, 'dark')\n",
    "\n",
    "# subdirectories for the 0.1-second g and r flats\n",
    "\n",
    "flat_directories_by_filter = {filter:os.path.join(calibration_directory, 'flat', filter)\n",
    "                              for filter in filters}\n",
    "\n",
    "# subdirectory for the biases (TheSky Professional Edition may indicate that these are 0.1-second darks)\n",
    "\n",
    "bias_directory = os.path.join(calibration_directory, 'bias')\n",
    "\n",
    "# Trimmed image reader utility (because the 3x3 binned images have a final row of zeros)\n",
    "\n",
    "def delete_last_rows_and_columns(arr, rows_to_delete, columns_to_delete):\n",
    "    row_count = np.shape(arr)[0]\n",
    "    arr = np.delete(arr, slice(row_count - rows_to_delete, row_count), 0)\n",
    "    column_count = np.shape(arr)[1]\n",
    "    arr = np.delete(arr, slice(column_count - columns_to_delete, column_count), 1)\n",
    "    return arr\n",
    "\n",
    "def trimmed_image_reader(file):\n",
    "    img = CCDData.read(file, unit=u.adu)\n",
    "    data = img.data\n",
    "    trimmed_data = delete_last_rows_and_columns(data, 1, 0)\n",
    "    img.data = trimmed_data\n",
    "    return img\n",
    "\n",
    "# darks\n",
    "\n",
    "dark_files = ImageFileCollection(dark_directory).files_filtered(include_path='True')\n",
    "darks = [trimmed_image_reader(file) for file in dark_files]\n",
    "\n",
    "# flats by filter\n",
    "\n",
    "flat_files_by_filter = {filter:ImageFileCollection(flat_directory).files_filtered(include_path='True')\n",
    "                        for filter, flat_directory in flat_directories_by_filter.items()}\n",
    "flats_by_filter = {filter:[trimmed_image_reader(file) for file in flat_files]\n",
    "                   for filter, flat_files in flat_files_by_filter.items()}\n",
    "                   \n",
    "# biases\n",
    "\n",
    "bias_files = ImageFileCollection(bias_directory).files_filtered(include_path='True')\n",
    "biases = [trimmed_image_reader(file) for file in bias_files]\n",
    "\n",
    "# Combine darks, flats, and biases\n",
    "\n",
    "calibration_combination_method = 'median'  # alternatively, the method can be 'average'\n",
    "\n",
    "master_dark = combine(darks, method=calibration_combination_method)\n",
    "master_flats_by_filter = {filter:combine(flats, method=calibration_combination_method)\n",
    "                         for filter, flats in flats_by_filter.items()}\n",
    "master_bias = combine(biases, method=calibration_combination_method)\n",
    "\n",
    "# Perform dark subtraction of the master flats\n",
    "\n",
    "master_flats_subtracted_by_filter = {filter:subtract_dark(master_flat,\n",
    "                                                          master_bias,\n",
    "                                                          data_exposure=flat_exposure,\n",
    "                                                          dark_exposure=bias_exposure,\n",
    "                                                          scale=False)\n",
    "                                     for filter, master_flat in master_flats_by_filter.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76465a34",
   "metadata": {},
   "source": [
    "## Load, Calibrate, Align, and Stack Lights\n",
    "\n",
    "What follows is a giant for loop, done once for each observation date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1ed037",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa.PIXEL_TOL = 2  # consider raising this from the default of 2 due to poor seeing or wind shake\n",
    "# THIS COMMENT IS THE LONGEST A LINE CAN BE AND STILL RENDER COMPLETELY WHEN PRINTING IN LANDSCAPE MODE.\n",
    "\n",
    "observation_dates = [\n",
    "    '2024-03-20',\n",
    "    '2024-03-21',\n",
    "    '2024-03-23',\n",
    "    '2024-03-27',\n",
    "    '2024-04-02',\n",
    "    '2024-04-03',\n",
    "    '2024-04-04',\n",
    "    '2024-04-06',\n",
    "    '2024-04-10',\n",
    "    '2024-04-11',\n",
    "    '2024-04-13',\n",
    "    '2024-04-17',\n",
    "    '2024-04-21',\n",
    "    '2024-04-22',\n",
    "    '2024-04-23',\n",
    "    '2024-04-29',\n",
    "    '2024-04-30',\n",
    "    '2024-05-02'\n",
    "]\n",
    "\n",
    "def hot_pixel_reject(image, sigma_multiple):\n",
    "    data = image.data\n",
    "    width, height = data.shape\n",
    "    with np.nditer(data, flags=['multi_index', 'buffered'], op_flags=['readwrite']) as it:\n",
    "        for x in it:\n",
    "            neighbors = 0.0\n",
    "            squares = 0.0\n",
    "            count = 0\n",
    "            i, j = it.multi_index\n",
    "            for ii in [i - 1, i, i + 1]:\n",
    "                # check for out of bounds column index (and skip if necessary)\n",
    "                if ii < 0 or ii >= width:\n",
    "                    continue\n",
    "                for jj in [j - 1, j, j + 1]:\n",
    "                    # check for out of bounds row index (and skip if necessary)\n",
    "                    if jj < 0 or jj >= height:\n",
    "                        continue\n",
    "                    # check for self (and skip if necessary)\n",
    "                    if ii == i and jj == j:\n",
    "                        continue\n",
    "                    neighbor = data[ii, jj]\n",
    "                    neighbors += neighbor\n",
    "                    squares += neighbor * neighbor\n",
    "                    count += 1\n",
    "            neighbors = neighbors / count  # now neighbors is the mean of the neighbors\n",
    "            squares = squares / count # now squares is the mean of the squares\n",
    "            sigma = math.sqrt((squares - neighbors * neighbors) * count / (count - 1))\n",
    "            x[...] = neighbors if abs(x - neighbors) >= sigma_multiple * sigma else x\n",
    "    return image\n",
    "\n",
    "for observation_date in observation_dates:\n",
    "    observation_directory = os.path.join(os.path.expanduser('~'), '2024 Sessions', observation_date)\n",
    "\n",
    "    # subdirectories for the 30-second g and r lights\n",
    "\n",
    "    light_directories_by_filter = {\n",
    "        filter:os.path.join(observation_directory, filter)\n",
    "        for filter in filters\n",
    "    }\n",
    "\n",
    "    # lights by filter\n",
    "\n",
    "    light_files_by_filter = {\n",
    "        filter:ImageFileCollection(light_directory).files_filtered(include_path='True')\n",
    "        for filter, light_directory in light_directories_by_filter.items()\n",
    "    }\n",
    "    \n",
    "    lights_by_filter = {\n",
    "        filter:[trimmed_image_reader(file) for file in light_files]\n",
    "        for filter, light_files in light_files_by_filter.items()\n",
    "    }\n",
    "\n",
    "    subtracted_lights_by_filter = {\n",
    "        filter:[subtract_dark(light,\n",
    "                              master_dark,\n",
    "                              data_exposure=light_exposure,\n",
    "                              dark_exposure=dark_exposure,\n",
    "                              scale=False) for light in lights]\n",
    "        for filter, lights in lights_by_filter.items()\n",
    "    }\n",
    "\n",
    "    # Perform flat division\n",
    "\n",
    "    calibrated_lights_by_filter = {\n",
    "        filter:[flat_correct(light, master_flats_subtracted_by_filter[filter]) for light in lights]\n",
    "        for filter, lights in subtracted_lights_by_filter.items()\n",
    "    }\n",
    "\n",
    "    # The horizontal lines in CMOS output can be removed with median subtraction\n",
    "\n",
    "    # Code would look something like:\n",
    "\n",
    "    # calibrated_medians = [\n",
    "    #     np.median(sample, axis=1, keepdims=True)\n",
    "    #     for sample in sample_calibrated_data_list\n",
    "    # ]\n",
    "\n",
    "    # calibrated_subtracted = [\n",
    "    #     sample_calibrated_data_list[i] - calibrated_medians[i]\n",
    "    #     for i in range(len(filters))\n",
    "    # ]\n",
    "\n",
    "    # TODO: FITS keywords that need to be asserted:\n",
    "\n",
    "    # NAXIS1  =                 1381 / length of data axis 1\n",
    "    # NAXIS2  =                  940 / length of data axis 2\n",
    "    # EXPTIME =                  30. / SBIGFITSEXT Total exposure time in seconds\n",
    "    # XBINNING=                    3 / SBIGFITSEXT Binning factor in width\n",
    "    # YBINNING=                    3 / SBIGFITSEXT Binning factor in height\n",
    "    # SET-TEMP=                   0. / SBIGFITSEXT The cooler setpoint in degrees C\n",
    "    # FILTER  = 'g       '           / SBIGFITSEXT The optical filter used to take ima\n",
    "\n",
    "    # Before we try to align these images we need to do hot pixel rejection\n",
    "    \n",
    "    hp_rejected_lights_by_filter = {\n",
    "        filter:[hot_pixel_reject(light, 5.0) for light in lights]\n",
    "        for filter, lights in calibrated_lights_by_filter.items()\n",
    "    }\n",
    "    \n",
    "    calibrated_directories_by_filter = {\n",
    "        filter:os.path.join(light_directory, 'calibrated')\n",
    "        for filter, light_directory in light_directories_by_filter.items()\n",
    "    }\n",
    "\n",
    "    for calibrated_directory in calibrated_directories_by_filter.values():\n",
    "        if not os.path.exists(calibrated_directory):\n",
    "            os.makedirs(calibrated_directory)\n",
    "            \n",
    "    # write the calibrated lights (these calibrated lights are also hot-pixel rejected)\n",
    "\n",
    "    for filter in filters:\n",
    "        lights = lights_by_filter[filter]\n",
    "        light_files = light_files_by_filter[filter]\n",
    "        hp_rejected_lights = hp_rejected_lights_by_filter[filter]\n",
    "        calibrated_directory = calibrated_directories_by_filter[filter]\n",
    "        for j in range(len(hp_rejected_lights)):\n",
    "            # Then we write all the files for that filter\n",
    "            light_header = lights[j][0].header\n",
    "            hp_rejected_data = hp_rejected_lights[j][0]\n",
    "            calibrated_file = os.path.join(calibrated_directory, os.path.basename(light_files[j]))\n",
    "            calibrated_file2 = os.path.splitext(calibrated_file)[0] + '_calibrated.fit'\n",
    "            fits.writeto(calibrated_file2, hp_rejected_data, light_header, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba069d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observation_dates = [\n",
    "#     # '2024-03-20',\n",
    "#     '2024-03-21',\n",
    "#     '2024-03-23',\n",
    "#     # '2024-03-27',\n",
    "#     # '2024-04-02',\n",
    "#     # '2024-04-03',\n",
    "#     # '2024-04-04',\n",
    "#     # '2024-04-06',\n",
    "#     # '2024-04-10',\n",
    "#     # '2024-04-11',\n",
    "#     '2024-04-13',\n",
    "#     # '2024-04-17',\n",
    "#     '2024-04-21',\n",
    "#     '2024-04-22',\n",
    "#     '2024-04-23',\n",
    "#     # '2024-04-29',\n",
    "#     # '2024-04-30',\n",
    "#     # '2024-05-02'\n",
    "# ]\n",
    "\n",
    "\n",
    "for _ in []:\n",
    "    \n",
    "    # In this phase of the analysis, the aligned directories are written to not read from.\n",
    "    \n",
    "    # create the aligned directories\n",
    "    \n",
    "    aligned_directories_by_filter = {\n",
    "        filter:os.path.join(light_directory, 'aligned')\n",
    "        for filter, light_directory in light_directories_by_filter.items()\n",
    "    }\n",
    "\n",
    "    for aligned_directory in aligned_directories_by_filter.values():\n",
    "        if not os.path.exists(aligned_directory):\n",
    "            os.makedirs(aligned_directory)\n",
    "\n",
    "    lights_aligned_with_footprints_by_filter = {\n",
    "        filter:[\n",
    "            # somewhat arbitrarily, we will use the image with index 10 as the reference light\n",
    "            aa.register(light, hp_rejected_lights_by_filter[filter][10], detection_sigma=3.0)\n",
    "            for light in lights\n",
    "        ]\n",
    "        for filter, lights in  hp_rejected_lights_by_filter.items()\n",
    "    }\n",
    "\n",
    "    # write the aligned lights\n",
    "\n",
    "    for filter in filters:\n",
    "        lights = lights_by_filter[filter]\n",
    "        light_files = light_files_by_filter[filter]\n",
    "        lights_aligned_with_footprints = lights_aligned_with_footprints_by_filter[filter]\n",
    "        aligned_directory = aligned_directories_by_filter[filter]\n",
    "        for j in range(len(lights_aligned_with_footprints)):\n",
    "            # Then we write all the files for that filter\n",
    "            light_header = lights[j][0].header\n",
    "            light_aligned_data = lights_aligned_with_footprints[j][0]\n",
    "            aligned_file = os.path.join(aligned_directory, os.path.basename(light_files[j]))\n",
    "            aligned_file2 = os.path.splitext(aligned_file)[0] + '_aligned.fit'\n",
    "            fits.writeto(aligned_file2, light_aligned_data, light_header, overwrite=True)\n",
    "\n",
    "    # read back in and stack the lights\n",
    "\n",
    "    aligned_lights_by_filter = {\n",
    "        filter:[CCDData.read(file, unit=u.adu)\n",
    "                for file in ImageFileCollection(aligned_directory).files_filtered(include_path='True')]\n",
    "        for filter, aligned_directory in aligned_directories_by_filter.items()\n",
    "    }\n",
    "\n",
    "    stacking_combination_method = 'average'  # alternatively, the method can be 'median'\n",
    "\n",
    "    combined_lights_by_filter = {\n",
    "        filter:combine(lights, method=stacking_combination_method)\n",
    "        for filter, lights in aligned_lights_by_filter.items()\n",
    "    }\n",
    "    \n",
    "    # create the directories where the stacked lights will be written\n",
    "\n",
    "    stacked_directory = os.path.join(analysis_directory, 'stacked')\n",
    "\n",
    "    if not os.path.exists(stacked_directory):\n",
    "        os.makedirs(stacked_directory)\n",
    "\n",
    "    # write the aligned lights\n",
    "\n",
    "    for filter in filters:\n",
    "        stacked_header = aligned_lights_by_filter[filter][0].header\n",
    "        stacked_data = combined_lights_by_filter[filter]\n",
    "        stacked_file = os.path.join(stacked_directory, observation_date + '-' + filter + '_stacked.fit')\n",
    "        fits.writeto(stacked_file, stacked_data, stacked_header, overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
